Diploidocus: Diploid genome assembly analysis tools.

```
Diploidocus v0.7.0
```

For a better rendering and navigation of this document, please download and open [`./docs/diploidocus.docs.html`](./docs/diploidocus.docs.html), or visit <https://slimsuite.github.io/diploidocus/>.
Documentation can also be generated by running Diploidocus with the `dochtml=T` option. (R and pandoc must be installed - see below.)

## Introduction

Diploidocus is a sequence analysis toolkit for a number of different analyses related to diploid genome assembly.
The main suite of analyses combines long read depth profiles, short read kmer analysis, assembly kmer analysis,
BUSCO gene prediction and contaminant screening for a number of assembly tasks including genome size prediction,
contamination identification, haplotig identification/removal and low quality contig/scaffold filtering. In addition,
Diploidocus has functions for removing redundancy, generating a non-redundant pseudo-diploid assembly with primary
and secondary scaffolds from 10x pseudohap output, and creating an in silico diploid set of long reads from two
haploid parents (for testing phasing etc.).

Please note that Diploidocus is still in development and documentation is currently a bit sparse.

The different run modes are set using `runmode=X`:

* `diploidocus` default run mode will run `gensize`, `telomeres`, `vecscreen` and `purgehap` analysis
* `gensize` uses BUSCO results, a BAM file and read file(s) to predict the genome size of the organism
* `purgehap` filters scaffolds based on post-processing of purge_haplotigs
* `telomeres` performs a regex telomere search based on method of https://github.com/JanaSperschneider/FindTelomeres
* `vecscreen` searches for contaminants and flags/masks/removes identified scaffolds
* `sortnr` performs an all-by-all mapping with minimap2 and then removes redundancy
* `diphap` splits a pseudodiploid assembly into primary and alternative scaffolds
* `diphapnr` runs `sortnr` followed by `diphap`
* `insilico` generates balanced diploid combined reads from two sequenced haploid parents

See <https://slimsuite.github.io/diploidocus/> for details of each mode. General SLiMSuite run documentation can be
found at <https://github.com/slimsuite/SLiMSuite>.

Diploidocus is available as part of SLiMSuite, or via a standalone GitHub repo at
<https://github.com/slimsuite/diploidocus>.

---

# Running Diploidocus

Diploidocus is written in Python 2.x and can be run directly from the commandline:

    python $CODEPATH/diploidocus.py [OPTIONS]

If running as part of [SLiMSuite](http://slimsuite.blogspot.com/), `$CODEPATH` will be the SLiMSuite `tools/`
directory. If running from the standalone [Diploidocus git repo](https://github.com/slimsuite/diploidocus), `$CODEPATH`
will be the path the to `code/` directory. Please see details in the [Diploidocus git repo](https://github.com/slimsuite/diploidocus)
for running on example data.

For `sortnr` and `diphapnr` mode, [minimap2](https://github.com/lh3/minimap2) must be installed and either added to the
environment `$PATH` or given to Diploidocus with the `minimap2=PROG` setting.

## Commandline options

A list of commandline options can be generated at run-time using the `-h` or `help` flags. Please see the general
[SLiMSuite documentation](http://slimsuite.blogspot.com/2013/08/command-line-options.html) for details of how to
use commandline options, including setting default values with **INI files**.

```
### ~ Main Diploidocus run options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
seqin=FILE      : Input sequence assembly [None]
runmode=X       : Diploidocus run mode [sortnr/diphap/diphapnr/purgehap/telomere/vecscreen/insilico/gensize]
basefile=FILE   : Root of output file names [diploidocus or $SEQIN basefile]
summarise=T/F   : Whether to generate and output summary statistics sequence data before and after processing [True]
genomesize=INT  : Haploid genome size (bp) [0]
dochtml=T/F     : Generate HTML Diploidocus documentation (*.docs.html) instead of main run [False]
tmpdir=PATH     : Path for temporary output files during forking (not all modes) [./tmpdir/]
### ~ Genome size prediction & Purge haplotigs options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
busco=TSVFILE   : BUSCO full table [full_table_$BASEFILE.busco.tsv]
bam=FILE        : BAM file of long reads mapped onto assembly [$BASEFILE.bam]
reads=FILELIST  : List of fasta/fastq files containing reads. Wildcard allowed. Can be gzipped. []
readtype=LIST   : List of ont/pb file types matching reads for minimap2 mapping [ont]
readbp=INT      : Total combined read length for depth calculations (over-rides reads=FILELIST) []
quickdepth=T/F  : Whether to use samtools depth in place of mpileup (quicker but underestimates?) [False]
kmerreads=FILELIST : File of high quality reads for KAT kmer analysis []
10xtrim=T/F     : Whether to trim 16bp 10x barcodes from Read 1 of Kmer Reads data for KAT analysis [False]
scdepth=INT     : Single copy ("diploid") read depth. If zero, will use SC BUSCO mode [0]
minmedian=INT   : Minimum median depth coverage to avoid low coverage filter [3]
phlow=INT       : Low depth cutoff for purge_haplotigs (-l X). Will use SCDepth/4 if zero. [0]
phmid=INT       : Middle depth for purge_haplotigs (-m X). Will derive from SCDepth if zero. [0]
phhigh=INT      : High depth cutoff for purge_haplotigs (-h X). Will use SCDepth x 2 if zero. [0]
zeroadjust=T/F  : Add zero coverage bases to purge_haplotigs LowPerc and adjust total [True]
includegaps=T/F : Whether to include gaps in the zero coverage bases for adjustment (see docs) [False]
mingap=INT      : Minimum length of a stretch of N bases to count as a gap for exclusion [10]
purgemode=X     : Rules used for purgehap analysis (simple/complex/nala) [complex]
### ~ Telomere options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
telofwd=X       : Regex for 5' telomere sequence search [C{2,4}T{1,2}A{1,3}]
telorev=X       : Regex for 5' telomere sequence search [T{1,3}A{1,2}G{2,4}]
telosize=INT    : Size of terminal regions (bp) to scan for telomeric repeats [50]
teloperc=PERC   : Percentage of telomeric region matching telomeric repeat to call as telomere [50]
### ~ VecScreen options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
screendb=FILE   : File of vectors/contaminants to screen out using blastn and VecScreen rules []
screenmode=X    : Action to take following vecscreen searching (report/mask/trim/purge) [report]
minvechit=INT   : Minimum length for a screendb match [50]
efdr=NUM        : Expected FDR threshold for VecScreen queries (0 is no filter) [1.0]
### ~ SortNR filtering/output options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
checkcov=PERC   : Percentage coverage for double-checking partial exact matches [95]
seqout=FILE     : Output sequence assembly [$BASEFILE.nr.fasta]
### ~ In silico diploid input/output options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
rqfilter=X      : Minimum RQ for output subreads [0]
lenfilter=X     : Min read length for filtered subreads [500]
parent1=FOFN    : File of file names for subreads fasta files on Parent 1. []
parent2=FOFN    : File of file names for subreads fasta files on Parent 2. []
See also SMRTSCAPE `summarise=T` options if `*.unique.tdt`/`*.smrt.tdt` have not been pre-generated with SMRTSCAPE.
### ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
```

---

# Diploidocus run modes

Details for the main Diploidocus run modes are given below.

**NOTE:** Diploidocus is under development and documentation might be a bit sparse. Please contact the author or
post an issue on GitHub if you have any questions.

---

## Main Diploidocus filtering [runmode=diploidocus]
Diploidocus builds on the PurgeHaplotigs classifications to use the depth bins, KAT assembly kmer frequencies and
BUSCO results to reclassify scaffolds and partition them into:

* `*.diploidocus.fasta` = the scaffolds kept for the next round of PurgeHap
* `*.core.fasta` = the same set of scaffolds, minus repeats
* `*.junk.fasta` = low coverage scaffolds, removed as junk
* `*.quarantine.fasta` = putative haplotigs, removed from the assembly but retained for reference.

**NOTE:** PurgeHaplotigs was not using zero coverage bases in its percentages. This is now fixed by Diploidocus.

_Further details coming soon!_

---

## Cycled Diploidocus filtering [runmode=dipcycle]
Diploidocus can be automated to cycle through repeated rounds of the main purge_haplotigs/filtering method until
no further scaffolds are removed. Each cycle will run Diploidocus with a numerical suffix, e.g. `$BASEFILE.1.*`,
using the `*.diploidocus.fasta` output from the previous cycle as input. Cycling will continue until no further
scaffolds are filtered into either `*.quarantine.fasta` or `*.junk.fasta`.

Final outputs from the final cycle will then be copied under the original `$BASEFILE` prefix:

* `$BASEFILE.diploidocus.tdt` = Final ratings for the final set of scaffolds. (See earlier cycles for purged.)
* `$BASEFILE.diploidocus.fasta` = the scaffolds kept from the final Diploidocus cycle
* `$BASEFILE.core.fasta` = the same set of scaffolds, minus repeats
* `$BASEFILE.quarantine.fasta` = concatenated purged scaffolds from all Diploidocus cycles.
* `$BASEFILE.junk.fasta` = concatenated low coverage and low quality scaffolds, removed as junk, from all cycles.

---

## Genome size prediction [runmode=gensize]
_Details coming soon!_

---

## Running Purge_haplotigs using BUSCO-guided cutoffs [runmode=purgehap]
_Coming soon! (Currently will run full diploidocus mode)_

---

## Telomere finding [runmode=telomere]
_Details coming soon!_

---

## Vector/contamination screening [runmode=vecscreen]
_Details coming soon!_

---

## Sorted non-redundant assembly cleanup [runmode=sortnr]

The sorted non-redundant assembly cleanup mode (`runmode=sortnr`) screens out any sequences that are 100% gap,
then removes any sequences that are 100% redundant with other sequences in the input. This includes full and
partial matches, i.e. if sequence X is wholly contained within sequence Y then X will be removed.

First, sequences are loaded from the file given with `seqin=FILE` and any [rje_seqlist](http://rest.slimsuite.unsw.edu.au/seqlist)
filters and sequence sorting are applied to the input. Sequences that are 100% Ns are removed and any gaps
exceeding 10 nt are reduced to 10 `N`s (`NNNNNNNNNN`) to prevent minimap2 from splitting sequences on long gaps.
These gap-reduced sequences are output to `$BASEFILE.tmp.fasta` and used for an all-by-all minimap2 search.

By default, minimap2 is run with the options to generate a `$BASEFILE.tmp.paf` file:

    --cs -p 0.0001 -t 4 -x asm20 -N 250

To modify minimap2 search settings, please see the [rje_paf](http://rest.slimsuite.unsw.edu.au/rje_paf)
documentation.

**NOTE:** These run options can probably be made more stringent to speed up minimap2 without loss of function.
Future releases may alter defaults accordingly.

Minimap2 output is parsed to identify scaffold-scaffold matches. Self-hits are ignored.
The minimum (gap-reduced) sequence length is used as a rapid parsing filter: any minimap2 matches that are less
than 95% of the query sequence (`Length`+`nn` fields) or less that 100% identity (`Identity`+`nn`)/(`Length`+`nn`)
are filtered during parsing.

**NOTE:** Future releases may feature an option to reduce the global percentage identity cut-off. Please contact
the author if you wish to see this implemented.

Minimap2 hits are then processed reverse-sorted by reference sequence size (e.g. scaffold length). Any hits
where either sequence has already been filtered are skipped. Otherwise, if the match (as determined by the
length of `:` regions in the CS string) matches the query length, the Query sequence will be flagged for
remove as "identical to" or "contained within" the Hit. (Mutually partial overlapping exact matches are NOT
filtered.) Filtered IDs and their matches are output to `$BASEFILE.redundant.txt`.

Once all sequences have been filtered, the remaining sequences are output to: `$BASEFILE.nr.fasta`.

**NOTE:** By default, sequences are output in the same order as in the input. To output in reverse size order,
add the `sortseq=invsize` command to the Diploidocus run command.

Finally, the input and output files are summarised (unless `summarise=F`) and statistics output to:
`$BASEFILE.summarise.tdt`.

Temporary gap-reduced and minimap2 PAF files are deleted unless running in `debug` or
`dev` modes.

---

## Pseudodiploid to primary and alternative haploptigs [runmode=diphap(nr)]

This protocol is based on 10x assemblies made for multiple organisms with supernova v2.0.0 and supernova v2.1.1.
In each case, some redundancy in output was discovered (a) within pseudohap output, and (b) in terms of fully
homozygous (identical) scaffolds shared by both haplotigs. It was also not entirely clear on what basis a
particular haplotype was assigned to pseudohap1 or pseudohap2.

The general workflow therefore sought to remove redundancy, generate a set of primary scaffolds based on scaffold
length, and generate a non-redundant set of alternative scaffolds where heterozygosity exists. If `diphapnr` mode
is used, the full workflow is implement by first running the `sortnr` workflow described above. In the reduced
`diphap` mode, redundancy is not removed first.

Sequences are loaded and matching haplotigs identified based on their names. Sequence names MUST end `HAP(\d+)`,
where `(\d+)` indicates an integer that matches up haplotigs (as produced by supernova pseudohap2 output, for
example). This is **not** a pipeline to identify haplotig pairs, it is purely for splitting identified
haplotigs into primary and alternative assemblies.

Processing itself is quite simple. Haplotig pairs are identified based on matching `HAP(\d+)` numbers. Where a
single haplotig is found, it is assigned as `diploid`, under the assumption that the two haplotigs were identical
and one was removed. (It is possible that only one parent had this scaffold, e.g. sex chromosomes, so some post-
processing of descriptions may be required.) If two haplotigs with the same number are identified, the longest
is assigned to `haploidA` and the shorter `haploidB`.

The **Primary Assemmbly** is then compiled from all `haploidA` and `diploid` sequences. These are given `pri`
prefixes and output to `$BASEFILE.pri.fasta`. The **Alternative** comprised of all `haploidB` sequences is output
to `$BASEFILE.alt.fasta`. If redundancy has been removed, this will likely be a subset of the full assembly. The
combined set of all primary and alternative sequences is output to `$BASEFILE.dipnr.fasta`.

**NOTE:** By default, sequences are output in the same order as in the input. To output in reverse size order,
add the `sortseq=invsize` command to the Diploidocus run command.

Finally, the input and output files are summarised (unless `summarise=F`) and statistics output to
`$BASEFILE.summarise.tdt`:

* `$BASEFILE.dipnr.fasta` = Combined pseudodiploid with `haploidA`, `haploidB` and `diploid` annotation.
* `$BASEFILE.pri.fasta` = Primary assembly with `haploidA` and `diploid` sequences.
* `$BASEFILE.alt.fasta` = Alternative assembly with `haploidB` sequences.


---

## In silico diploid generator [runmode=insilico]

This module generates balanced "in silico diploid" PacBio subread data from two sequenced haploid parents. Each
parent must first be run through SMRTSCAPE to generate subread summary data. (This will be performed if missing. Each
parent needs a `*.fofn` file of subread file names, `*.unique.tdt` unique subreads table and `*.smrt.tdt` SMRT cell
identifier table.)

A new set of subreads is then generated from the combined set of parent subreads. This is done by first ranking the
unique subreads from each parent by length. First, the longest subread from each parent are compared and the shortest
selected to be the first subread of the diploid. (The shortest is taken to minimise length differences between the
two parents.) Next, the longest subread from the next parent that is no longer than the previous subread is added.
This cycles, picking a read from the the parent with fewest cumulative bases each cycle. The longest subread that is
no longer than the previous subread is selected. This continues until one parent runs out of subreads. Additional
subreads will be added from the other parent if they reduce the difference in cumulative output for each parent, or
until `lenfilter=X` is reached.

Final output will be a `*.LXXXRQXX.fasta` file in which each parent has a similar total sequence content and for
which the subread length distributions should also be similar. This is to overcome biases in resulting diploid
assemblies, where one parent has higher quality data than the other.

NOTE: If performing downstream filtering by Read Quality (RQ), this might reintroduce a bias if one parent has much
higher RQ values than the other. The `rqfilter=X` setting can therefore be used to restrict output to  reads with a
minimum RQ value. By default this is 0.84. If you do not get enough sequence output, this setting may need to be
relaxed. Similarly, only sequences above `lenfilter=X` in length will be output. These are the figures given in the
`LXXXRQXX` part of the output file, e.g. defaults of RQ>=0.84 and Len>=500 generates `*.L500RQ84.fas`.


<br>
<small>&copy; 2019 Richard Edwards | richard.edwards@unsw.edu.au</small>
